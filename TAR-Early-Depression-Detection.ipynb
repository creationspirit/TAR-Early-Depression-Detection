{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "from lxml import etree\n",
    "from operator import itemgetter\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from scipy.sparse import vstack, hstack, coo_matrix\n",
    "\n",
    "from empath import Empath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity(arg):\n",
    "    \"\"\"\n",
    "    Simple identity function works as a passthrough.\n",
    "    \"\"\"\n",
    "    return arg\n",
    "\n",
    "def show_most_informative_features(vectorizer, classifier, text=None, n=20):\n",
    "    \"\"\"\n",
    "    Accepts a Pipeline with a classifer and a TfidfVectorizer and computes\n",
    "    the n most informative features of the model. If text is given, then will\n",
    "    compute the most informative features for classifying that text.\n",
    "\n",
    "    Note that this function will only work on linear models with coefs_\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {} model.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = classifier.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        key=itemgetter(0), reverse=True\n",
    "    )\n",
    "\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\"Classified as: {}\".format(classifier.predict([text])))\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(cp, fnp, cn, fnn)\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for Corpus preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw_diff = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves'}\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, stopwords=None, punct=None,\n",
    "                 lower=True, strip=True):\n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.stopwords  = stopwords or set(sw.words('english'))\n",
    "        self.stopwords.difference_update(sw_diff)\n",
    "        self.punct      = punct or set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "\n",
    "    def transform(self, X, method='lem'):\n",
    "        return [\n",
    "            list(self.tokenize(doc, method)) for doc in X\n",
    "        ]   \n",
    "\n",
    "    def tokenize(self, document, method='lem'):\n",
    "        if(method == 'lem'):\n",
    "            # Break the document into sentences\n",
    "            for sent in sent_tokenize(document):\n",
    "                # Break the sentence into part of speech tagged tokens\n",
    "                for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                    # Apply preprocessing to the token\n",
    "                    token = self.process_token(token)\n",
    "                    if not self.is_valid_token(token):\n",
    "                        continue\n",
    "                        \n",
    "                    # Lemmatize the token and yield\n",
    "                    lemma = self.lemmatize(token, tag)\n",
    "                    yield lemma\n",
    "                    \n",
    "        elif(method == 'stem'):\n",
    "            # Break the document into tokens\n",
    "            for token in wordpunct_tokenize(document):\n",
    "                # Apply preprocessing to the token\n",
    "                token = self.process_token(token)\n",
    "                if not self.is_valid_token(token):\n",
    "                    continue\n",
    "                \n",
    "                stem = self.stem(token)\n",
    "                yield stem\n",
    "        else:\n",
    "            raise ValueError('Unknown method type.')\n",
    "\n",
    "    def lemmatize(self, token, tag):\n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)\n",
    "    \n",
    "    def stem(self, token):\n",
    "        return self.stemmer.stem(token)\n",
    "    \n",
    "    def process_token(self, token):\n",
    "        token = token.lower() if self.lower else token\n",
    "        token = token.strip() if self.strip else tcharoken\n",
    "        token = token.strip('_') if self.strip else token\n",
    "        token = token.strip('*') if self.strip else token\n",
    "        return token\n",
    "    \n",
    "    def is_valid_token(self, token):\n",
    "        # If stopword, token is invalid\n",
    "        if token in self.stopwords:\n",
    "            return False\n",
    "\n",
    "        # If punctuation, token is invalid\n",
    "        if all(char in self.punct for char in token):\n",
    "            return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of code loads data corpus from multiple files into lists X (texts) and y(labels) with one entry per user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_entries(X, y, path_list, label_dict=None, default_label=0):\n",
    "    entry_lists = []\n",
    "    for path in path_list:\n",
    "        entry_lists.append(os.scandir(path))\n",
    "    \n",
    "    IMAGE_STR = 'data:image'\n",
    "    \n",
    "    for list_of_entries in entry_lists:\n",
    "        for entry in list_of_entries:\n",
    "            root = etree.parse(entry.path).getroot()\n",
    "            user_id = root[0].text\n",
    "        \n",
    "            user_text = ''\n",
    "            for post in root.findall('.//TITLE') + root.findall('.//TEXT'):\n",
    "                post = post.text.strip().strip()\n",
    "                if post != '':\n",
    "                    if IMAGE_STR in post:\n",
    "                        continue\n",
    "                    post = re.sub(r\"http\\S+\", \" \", post)\n",
    "                    post = re.sub(r\"\\d+\", \" \", post)\n",
    "                    post = re.sub(u\"\\xa0\", \" \", post)\n",
    "                    post = re.sub(u\"\\\\p{P}+\", \" \", post)\n",
    "                    user_text += ' ' + post\n",
    "            \n",
    "            X.append(user_text)\n",
    "            label = int(label_dict[user_id]) if label_dict else default_label\n",
    "            y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility methods for extracting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg_sentence_length(sentences):\n",
    "    sum = 0\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.replace(' ', '')\n",
    "        sum += len(sentence)\n",
    "    return sum / len(sentences) if sentences else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_features(X_times, X_sentence_lengths, X_post_cnt, path_list):\n",
    "    entry_lists = []\n",
    "    for path in path_list:\n",
    "        entry_lists.append(os.scandir(path))\n",
    "        \n",
    "    IMAGE_STR = 'data:image'\n",
    "    \n",
    "    for list_of_entries in entry_lists:\n",
    "        for entry in list_of_entries:\n",
    "            root = etree.parse(entry.path).getroot()\n",
    "            user_id = root[0].text\n",
    "            \n",
    "            sentences = []\n",
    "            post_cnt = 0\n",
    "            for post in root.findall('.//TEXT'):\n",
    "                post_cnt += 1\n",
    "                post = post.text.strip().strip()\n",
    "                if post != '':\n",
    "                    sentences.extend(sent_tokenize(post))\n",
    "            avg_sentence_length = get_avg_sentence_length(sentences)\n",
    "            \n",
    "            sum_hours = 0\n",
    "            post_cnt = 0\n",
    "            for date in root.findall('.//DATE'):\n",
    "                date = date.text.strip()\n",
    "                if date != '':\n",
    "                    post_cnt += 1\n",
    "                    m = re.match(r'\\d{4}-\\d{2}-\\d{2} (\\d{2}).*', date)\n",
    "                    hour = int(m.group(1))\n",
    "                    sum_hours += hour\n",
    "            \n",
    "            time = [0] * 12\n",
    "            avg_hour = sum_hours / post_cnt\n",
    "            index = int(avg_hour // 2)\n",
    "            time[index] = 1\n",
    "            \n",
    "            X_post_cnt.append([post_cnt])\n",
    "            X_sentence_lengths.append([avg_sentence_length])\n",
    "            X_times.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading input files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "TRAIN_PATH = os.path.join(cwd, \"reddit-training-ready-to-share\")\n",
    "TEST_PATH = os.path.join(cwd, \"reddit-test-data-ready-to-share\")\n",
    "\n",
    "TRAIN_POSITIVE_PATH = os.path.join(TRAIN_PATH, \"positive_examples_anonymous\")\n",
    "TRAIN_NEGATIVE_PATH = os.path.join(TRAIN_PATH, \"negative_examples_anonymous\")\n",
    "\n",
    "TEST_POSITIVE_PATH = os.path.join(TEST_PATH, \"positive_examples_anonymous\")\n",
    "TEST_NEGATIVE_PATH = os.path.join(TEST_PATH, \"negative_examples_anonymous\")\n",
    "\n",
    "TRAIN_LABELS_PATH = os.path.join(cwd, 'risk_golden_truth.txt')\n",
    "\n",
    "IMAGE_STR = 'data:image'\n",
    "\n",
    "train_labels_file = open(TRAIN_LABELS_PATH, 'r')\n",
    "train_label_dict = {}\n",
    "for line in train_labels_file:\n",
    "    xml_file, label = line.split(' ')\n",
    "    train_label_dict[xml_file] = label\n",
    "train_labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = []\n",
    "y_train = []\n",
    "X_test_raw = []\n",
    "y_test = []\n",
    "\n",
    "train_entry_path_list = [TRAIN_POSITIVE_PATH, TRAIN_NEGATIVE_PATH]\n",
    "test_pos_entry_path_list = [TEST_POSITIVE_PATH]\n",
    "test_neg_entry_path_list = [TEST_NEGATIVE_PATH]\n",
    "\n",
    "read_entries(X=X_train_raw, y=y_train, path_list=train_entry_path_list, label_dict=train_label_dict)\n",
    "read_entries(X=X_test_raw, y=y_test, path_list=test_pos_entry_path_list, default_label=1)\n",
    "read_entries(X=X_test_raw, y=y_test, path_list=test_neg_entry_path_list, default_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_times_train = []\n",
    "X_times_test = []\n",
    "\n",
    "X_sentence_len_train = []\n",
    "X_sentence_len_test = []\n",
    "\n",
    "X_post_cnt_train = []\n",
    "X_post_cnt_test = []\n",
    "\n",
    "read_features(X_times=X_times_train, X_sentence_lengths=X_sentence_len_train, X_post_cnt=X_post_cnt_train,\n",
    "              path_list=train_entry_path_list)\n",
    "read_features(X_times=X_times_test, X_sentence_lengths=X_sentence_len_test, X_post_cnt=X_post_cnt_test,\n",
    "              path_list=test_pos_entry_path_list)\n",
    "read_features(X_times=X_times_test, X_sentence_lengths=X_sentence_len_test, X_post_cnt=X_post_cnt_test,\n",
    "              path_list=test_neg_entry_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1783,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_semantic_features(X):\n",
    "    lexicon = Empath()\n",
    "    relevant_lexical_categories = ['negative_emotion'\n",
    "                              ]\n",
    "    \n",
    "    # not so good: speaking, business\n",
    "    # good for LR: negative_emotion, positive_emotion, communication, violence, business, nervousness,\n",
    "    # body, pain, sexual, healing, internet\n",
    "    \n",
    "    # maybe: government, kill, politics, envy\n",
    "    relevant_lexical_categories2 = ['negative_emotion', 'positive_emotion', 'communication',\n",
    "                                    'violence', 'business', 'nervousness', 'body', 'pain',\n",
    "                                    'internet', 'work', 'shame', 'poor'\n",
    "                              ]\n",
    "    feature_mat = []\n",
    "    for text in X:\n",
    "        #d = lexicon.analyze(text, categories=['negative_emotion'], normalize=True)\n",
    "        #feature_mat.append(list(d.values()))\n",
    "        \n",
    "        # u slucaju vise featura sljedeca linija ih sortira\n",
    "        d = lexicon.analyze(text, categories=relevant_lexical_categories2, normalize=True)\n",
    "        feature_mat.append([d[key] for key in sorted(d.keys(), reverse=False)])\n",
    "    return feature_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sem_feat_train = get_semantic_features(X_train_raw)\n",
    "X_sem_feat_test = get_semantic_features(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use X list as input to NLTKPreprocessor class which outputs list of preprocessed, tokenized texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = NLTKPreprocessor()\n",
    "preprocess_method = 'stem'\n",
    "X_train_prep = preprocessor.transform(X_train_raw, method=preprocess_method)\n",
    "X_test_prep = preprocessor.transform(X_test_raw, method=preprocess_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use tf-idf vectorizer for vector representation of the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=identity, preprocessor=None, lowercase=False, ngram_range=(1, 1), min_df=30)\n",
    "X_train = vect.fit_transform(X_train_prep, y_train)\n",
    "X_test = vect.transform(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding hand-picked features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k='all')\n",
    "X_kbest_train = chi2_selector.fit_transform(X_train, y_train)\n",
    "X_kbest_test = chi2_selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing and adding features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1786,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_abs_scaler = MaxAbsScaler()\n",
    "X_sentence_len_train_scaled = max_abs_scaler.fit_transform(X_sentence_len_train)\n",
    "X_sentence_len_test_scaled = max_abs_scaler.transform(X_sentence_len_test)\n",
    "\n",
    "X_sem_feat_train_scaled = max_abs_scaler.fit_transform(X_sem_feat_train)\n",
    "X_sem_feat_test_scaled = max_abs_scaler.transform(X_sem_feat_test)\n",
    "\n",
    "X_post_cnt_train_scaled = max_abs_scaler.fit_transform(X_post_cnt_train)\n",
    "X_post_cnt_test_scaled = max_abs_scaler.transform(X_post_cnt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1787,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = hstack([X_kbest_train, X_times_train, X_sentence_len_train_scaled,\n",
    "                    X_sem_feat_train_scaled, X_post_cnt_train_scaled])\n",
    "\n",
    "X_test_2 = hstack([X_kbest_test, X_times_test, X_sentence_len_test_scaled,\n",
    "                   X_sem_feat_test_scaled, X_post_cnt_test_scaled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and evaluating models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: SVM classifier\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9612    0.9148    0.9374       352\n",
      "          1     0.5775    0.7593    0.6560        54\n",
      "\n",
      "avg / total     0.9102    0.8941    0.9000       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: SVM classifier\")\n",
    "\n",
    "model = LinearSVC(class_weight='balanced')\n",
    "model.fit(X_train_2, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model.predict(X_test_2)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: LogisticRegression classifier\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9664    0.8182    0.8862       352\n",
      "          1     0.4074    0.8148    0.5432        54\n",
      "\n",
      "avg / total     0.8921    0.8177    0.8405       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: LogisticRegression classifier\")\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train_2, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model.predict(X_test_2)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: Voting classifier (SVM + LR)\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9525    0.9119    0.9318       352\n",
      "          1     0.5507    0.7037    0.6179        54\n",
      "\n",
      "avg / total     0.8991    0.8842    0.8900       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: Voting classifier (SVM + LR)\")\n",
    "\n",
    "model1 = LogisticRegression(class_weight='balanced')\n",
    "model2 = SVC(class_weight='balanced', kernel='linear', probability=True)\n",
    "model = VotingClassifier(estimators=[('svm', model1), ('lr', model2)], voting='soft', weights=[2, 1])\n",
    "model.fit(X_train_2, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model.predict(X_test_2)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the complete model on whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vstack((X_train_2, X_test_2))\n",
    "y = y_train + y_test\n",
    "\n",
    "model_complete = LogisticRegression(class_weight='balanced')\n",
    "model_complete.fit(X, y)\n",
    "\n",
    "print(\"Complete model fit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most informative features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(show_most_informative_features(vect, model_complete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some baseline classifier testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer(tokenizer=identity, preprocessor=None, lowercase=False, ngram_range=(1, 2), min_df=20)\n",
    "X_train_3 = vect2.fit_transform(X_train_prep, y_train)\n",
    "X_test_3 = vect2.transform(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: BernoulliNB classifier\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.59      0.73       352\n",
      "          1       0.25      0.89      0.39        54\n",
      "\n",
      "avg / total       0.88      0.63      0.69       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: BernoulliNB classifier\")\n",
    "\n",
    "model2 = BernoulliNB()\n",
    "model2.fit(X_train_3, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model2.predict(X_test_3)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: MultinomialNB classifier\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.65      0.78       352\n",
      "          1       0.28      0.91      0.43        54\n",
      "\n",
      "avg / total       0.89      0.68      0.73       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: MultinomialNB classifier\")\n",
    "\n",
    "model3 = MultinomialNB()\n",
    "model3.fit(X_train_3, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model3.predict(X_test_3)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building for evaluation: DecisionTree classifier\n",
      "Evaluation model fit\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9096    0.9148    0.9122       352\n",
      "          1     0.4231    0.4074    0.4151        54\n",
      "\n",
      "avg / total     0.8449    0.8473    0.8461       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building for evaluation: DecisionTree classifier\")\n",
    "\n",
    "model4 = DecisionTreeClassifier(class_weight='balanced')\n",
    "model4.fit(X_train_2, y_train)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model4.predict(X_test_2)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Building for evaluation: RandomForest classifier\")\n",
    "\n",
    "model4 = RandomForestClassifier(class_weight='balanced')\n",
    "model4.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(\"Evaluation model fit\")\n",
    "print(\"Classification Report:\\n\")\n",
    "\n",
    "y_pred = model4.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Empath testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexicon = Empath()\n",
    "relevant_lexical_categories1 = ['help', 'medical_emergency', 'hate', 'health', 'suffering', \n",
    "                               'kill', 'fear', 'death', 'violence', 'love',\n",
    "                               'anonymity', 'injury', 'appearance', 'sadness',\n",
    "                               'emotional', 'ugliness', 'shame', 'torment',\n",
    "                               'pain', 'negative_emotion', 'positive_emotion', 'friends',\n",
    "                               'alcohol', 'nervousness', 'optimism', 'body', 'contentment'\n",
    "                               'cold', 'school', 'communication', 'work', 'sleep', 'play'\n",
    "                               'trust', 'social_media', 'sexual'\n",
    "                              ]\n",
    "\n",
    "relevant_lexical_categories = ['negative_emotion', 'speaking', 'positive_emotion', 'communication',\n",
    "                               'friends', 'children', 'optimism', 'violence', 'pain', 'family',\n",
    "                               'trust', 'love', 'party', 'business', 'home', 'shame', 'listen',\n",
    "                               'giving', 'body', 'suffering', 'work', 'nervousness', 'strength',\n",
    "                               'hearing', 'health', 'traveling', 'wedding', 'childish', 'hate',\n",
    "                               'social_media', 'sadness', 'school'\n",
    "                              ]\n",
    "\n",
    "x_senti1 = []\n",
    "y_senti1 = []\n",
    "read_entries(X=x_senti1, y=y_senti1, path_list=test_pos_entry_path_list, default_label=1)\n",
    "\n",
    "x_senti2 = []\n",
    "y_senti2 = []\n",
    "read_entries(X=x_senti2, y=y_senti2, path_list=test_neg_entry_path_list, default_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_emotion 0.012248940363096133\n",
      "speaking 0.009105782739319442\n",
      "positive_emotion 0.008995339285036368\n",
      "communication 0.008830249850341204\n",
      "friends 0.00846497832125068\n",
      "children 0.006931161375642563\n",
      "optimism 0.006519832103539315\n",
      "violence 0.006218428262115479\n",
      "pain 0.005941038981843784\n",
      "family 0.00550452674565939\n",
      "trust 0.005347166562256074\n",
      "love 0.005207327531059792\n",
      "party 0.005187753882133287\n",
      "business 0.005014333316133\n",
      "home 0.004927324087337118\n",
      "shame 0.004891296110924743\n",
      "listen 0.0048506269565884285\n",
      "giving 0.004849849188220808\n",
      "body 0.004644642245471797\n",
      "suffering 0.004412367422399614\n",
      "work 0.004372578904294599\n",
      "nervousness 0.004197818754924981\n",
      "strength 0.0041658065969598385\n",
      "hearing 0.003941282497842366\n",
      "health 0.003886351483086154\n",
      "traveling 0.0038119502711799025\n",
      "wedding 0.0037394964886116404\n",
      "childish 0.0037337684741891664\n",
      "hate 0.003720763522888411\n",
      "social_media 0.0036466073348802356\n",
      "sadness 0.003608014968048969\n",
      "school 0.0035693720200083556\n",
      "reading 0.0035138774970333514\n",
      "youth 0.0035046709316978674\n",
      "play 0.0034733430498384743\n",
      "healing 0.003472627025024236\n",
      "internet 0.0034316516789521224\n",
      "cold 0.0033704520765899283\n",
      "phone 0.003329761271535313\n",
      "celebration 0.00332557764414653\n",
      "emotional 0.0032328121345364825\n",
      "shape_and_size 0.0032032031303542144\n",
      "contentment 0.0031845248371669107\n",
      "death 0.00317554344138004\n",
      "college 0.0030952579628614574\n",
      "help 0.0030345330442514006\n",
      "music 0.002997745413442134\n",
      "domestic_work 0.0029734319995770447\n",
      "sports 0.0029484517671887443\n",
      "writing 0.002922422437205821\n",
      "leisure 0.0028770534265188824\n",
      "meeting 0.0028532130387393224\n",
      "movement 0.002839596917509766\n",
      "appearance 0.002829539342959123\n",
      "messaging 0.0027029564121022\n",
      "vacation 0.0026669351770864133\n",
      "attractive 0.002637558467009235\n",
      "swearing_terms 0.0025975082097606963\n",
      "injury 0.002590547247090245\n",
      "money 0.002562481649782025\n",
      "fun 0.002527778369158089\n",
      "feminine 0.0025004035038169313\n",
      "eating 0.002407369529703255\n",
      "dispute 0.00240423433304553\n",
      "shopping 0.002399429606712164\n",
      "affection 0.0023240703576871283\n",
      "economics 0.00231597715747209\n",
      "fear 0.0022471853495368895\n",
      "toy 0.0022358570790298993\n",
      "order 0.0022042808211069896\n",
      "sexual 0.0021799770918140933\n",
      "medical_emergency 0.0021099138298857983\n",
      "computer 0.0020501908183369866\n",
      "musical 0.0020442545389899925\n",
      "occupation 0.0019308406054685703\n",
      "achievement 0.0019243915966350258\n",
      "technology 0.0018866955700751482\n",
      "breaking 0.001836553745604052\n",
      "sleep 0.001831181904675167\n",
      "real_estate 0.0018154875310795458\n",
      "masculine 0.001802136610684244\n",
      "restaurant 0.0017866864902426366\n",
      "valuable 0.0017754110738958722\n",
      "confusion 0.0017038965867365733\n",
      "art 0.0017007302759915548\n",
      "driving 0.0016999691330540623\n",
      "cooking 0.0016874645764832132\n",
      "neglect 0.0016592776524009152\n",
      "office 0.0016386045464513237\n",
      "heroic 0.0016040526475237238\n",
      "sound 0.00156243949472351\n",
      "fight 0.0015112557628449246\n",
      "night 0.0015006162165990804\n",
      "clothing 0.0014947654749444355\n",
      "science 0.001488124124254177\n",
      "payment 0.001481994033888827\n",
      "white_collar_job 0.0014526420318254818\n",
      "banking 0.0013567015362830341\n",
      "competing 0.0013254072300130284\n",
      "weapon 0.0013043645244211098\n",
      "dance 0.001302103975444366\n",
      "noise 0.001288138957082132\n",
      "kill 0.0012796909685645337\n",
      "vehicle 0.0012794274000538816\n",
      "programming 0.0012762926728417862\n",
      "aggression 0.0012251926608590636\n",
      "car 0.0012167876362105907\n",
      "divine 0.0011909145982882641\n",
      "war 0.0011798770761628715\n",
      "lust 0.0011595626319919896\n",
      "timidity 0.0011571995335770437\n",
      "hipster 0.00115362874807869\n",
      "power 0.0011444884699505036\n",
      "beauty 0.0011416240157379018\n",
      "cleaning 0.001121453558157545\n",
      "animal 0.0011118927663540054\n",
      "morning 0.0010971368095637024\n",
      "journalism 0.001096824392585894\n",
      "furniture 0.0010930824429153817\n",
      "leader 0.0010847700770646445\n",
      "fabric 0.0010541999124355158\n",
      "alcohol 0.0010496487738758556\n",
      "liquid 0.0010344871656989378\n",
      "exercise 0.0010333817230088224\n",
      "politeness 0.0010329623883487658\n",
      "poor 0.0010266856660113412\n",
      "weather 0.0010150826119328523\n",
      "ridicule 0.0009944592632174557\n",
      "crime 0.0009846300863753997\n",
      "sympathy 0.0009381332992870185\n",
      "fashion 0.0008984039389548027\n",
      "cheerfulness 0.0008801037892697039\n",
      "gain 0.0008710813395473156\n",
      "legend 0.0008497213791107865\n",
      "zest 0.000849161400580738\n",
      "joy 0.0008462013242650498\n",
      "law 0.0008352821509231228\n",
      "ancient 0.0008270281420049232\n",
      "pet 0.0008230353894916361\n",
      "hygiene 0.0008179773868435063\n",
      "deception 0.000783316188246016\n",
      "horror 0.0007750568427075961\n",
      "government 0.0007721939078415786\n",
      "wealthy 0.0007679913406055263\n",
      "torment 0.0007535292842129759\n",
      "fire 0.0007471737823786454\n",
      "stealing 0.0007363032330141569\n",
      "rural 0.0007299599669843852\n",
      "magic 0.0007082053702091234\n",
      "blue_collar_job 0.0007040368947477545\n",
      "urban 0.0006738617820223446\n",
      "dominant_personality 0.0006658863728595349\n",
      "air_travel 0.0006627706462400184\n",
      "envy 0.000641629144916635\n",
      "tool 0.0006395450416782798\n",
      "smell 0.0006299702169149931\n",
      "weakness 0.0006263658184591067\n",
      "anger 0.0006256278057666074\n",
      "ugliness 0.0006248597921106731\n",
      "prison 0.0006201128695778566\n",
      "ocean 0.0006199916863892003\n",
      "military 0.0006127947236337143\n",
      "worship 0.0005935125724289557\n",
      "surprise 0.0005503878002591525\n",
      "philosophy 0.0005471058329947084\n",
      "warmth 0.0005285150771685956\n",
      "negotiate 0.0005281659562841467\n",
      "water 0.0005248540015269098\n",
      "religion 0.0005221070001212309\n",
      "plant 0.0004909069999792754\n",
      "sailing 0.0004842363948426147\n",
      "monster 0.0004674122364297934\n",
      "beach 0.0004551720397856849\n",
      "hiking 0.00045205377300264134\n",
      "royalty 0.0004064238240085531\n",
      "politics 0.00039413521521919603\n",
      "independence 0.0003765560597592562\n",
      "disappointment 0.0003707487266042265\n",
      "swimming 0.0003658606664371725\n",
      "rage 0.0003642801429030068\n",
      "anticipation 0.000363185664482567\n",
      "pride 0.00035790896659808623\n",
      "tourism 0.00035351827995107343\n",
      "disgust 0.0003460972140337595\n",
      "dominant_heirarchical 0.00032650753584399816\n",
      "ship 0.00029111429107884324\n",
      "irritability 0.0002554928214378073\n",
      "medieval 0.00025248303498359443\n",
      "farming 0.00020238033843324806\n",
      "superhero 0.00019718292906187017\n",
      "exasperation 0.00017525108061054682\n",
      "terrorism 0.00016683353515975632\n",
      "exotic 0.00015705765246131018\n",
      "anonymity 0.00013572909943680933\n"
     ]
    }
   ],
   "source": [
    "avg_dict1 = {}\n",
    "len1 = len(x_senti1)\n",
    "for i in x_senti1:\n",
    "    d = lexicon.analyze(i, normalize=True)\n",
    "    avg_dict1 = { k: d.get(k, 0)/len1 + avg_dict1.get(k, 0) for k in set(d) | set(avg_dict1) }\n",
    "    #d = {k: v for k, v in d.items() if v > 0}\n",
    "    \n",
    "for k, v in sorted(avg_dict1.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dict2 = {}\n",
    "len2 = len(x_senti2)\n",
    "for i in x_senti2:\n",
    "    d = lexicon.analyze(i, normalize=True)\n",
    "    avg_dict2 = { k: d.get(k, 0)/len2 + avg_dict2.get(k, 0) for k in set(d) | set(avg_dict2) }\n",
    "    #d = {k: v for k, v in d.items() if v > 0}\n",
    "    \n",
    "for k, v in sorted(avg_dict2.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(lexicon.analyze(x_senti2[2], normalize=True).values()))\n",
    "d = lexicon.analyze(x_senti2[2], normalize=True)\n",
    "for w in sorted(d.keys(), reverse=False):\n",
    "    print(w, d[w])\n",
    "\n",
    "result = [d[key] for key in sorted(d.keys(), reverse=False)]\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is not exactly a big deal, but a huge sigh of relief to get confirmation that the movie is on the right track.', 'I love life.']\n"
     ]
    }
   ],
   "source": [
    "sen = 'It is not exactly a big deal, but a huge sigh of relief to get confirmation that the movie is on the right track. I love life.'\n",
    "print(sent_tokenize(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_i = []\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i] != y_pred[i]):\n",
    "        user_i.append(i)\n",
    "\n",
    "entry_lists = []\n",
    "path_list = test_pos_entry_path_list + test_neg_entry_path_list\n",
    "for path in path_list:\n",
    "    entry_lists.append(os.scandir(path))\n",
    "    \n",
    "users = []\n",
    "\n",
    "for list_of_entries in entry_lists:\n",
    "    for entry in list_of_entries:\n",
    "        root = etree.parse(entry.path).getroot()\n",
    "        user_id = root[0].text\n",
    "        users.append(user_id)\n",
    "\n",
    "for i in user_i:\n",
    "    print(users[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lexicon.analyze(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3]])\n",
    "print(a.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
